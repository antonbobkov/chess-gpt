{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6af8d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "tokens_filepath = \"C:\\\\Users\\\\anton\\\\Documents\\\\code\\\\chessGPT\\\\data\\\\tokens.txt\"\n",
    "intermediate_filepath = \"C:\\\\Users\\\\anton\\\\Documents\\\\code\\\\chessGPT\\\\data\\\\intermediate.txt\"\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "157b9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tokens_filepath, \"r\") as f:\n",
    "    tokens = f.read().splitlines()\n",
    "    \n",
    "tokens = [\"SPECIAL\"] + tokens\n",
    "\n",
    "# print (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5013585",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_int = {}\n",
    "int_to_token = {}\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    token_to_int[token] = i\n",
    "    int_to_token[i] = token\n",
    "    \n",
    "# print (token_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f726ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(lst):\n",
    "    return [token_to_int[token] for token in lst]\n",
    "def decode(lst):\n",
    "    return [int_to_token[i] for i in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8ff8b302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokens)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9e10c7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([167, 184,  80,  83,  42, 164,  38, 144,  34,  48,  48, 269, 148, 175,\n",
      "        169, 136, 266, 276,  18,  83,  84,  85, 257,  79,  86,  79, 266, 104,\n",
      "         92, 124,  74,  20, 326,  74, 267, 267, 320, 117, 318, 331,  94,   6,\n",
      "        127,  20, 332,  99, 333, 237, 312,  23, 305, 313, 347, 224, 207, 235,\n",
      "         70,  69, 227, 216, 210,  30, 358,  69, 108, 340,  14, 353,  67, 204,\n",
      "        131, 338, 331, 196,  72,  69, 114, 233,  69, 231,  72,  71,  19,  67,\n",
      "        117,  66,  26,  65, 120,  71])\n",
      "tensor([147, 164, 207, 183,  57,  83,  84,  20,  74,  74, 331, 103, 168, 144,\n",
      "        174,  86, 151,  85, 152,  11,  80,  81,  93,  20,  97,  87, 107,  90,\n",
      "         84,  79, 348,  15, 341,  48,  22,  43,  15, 268,  78, 326,  80, 331,\n",
      "        319,  34, 109, 259, 239, 243, 266, 311,  79, 250,  80, 266,  80, 264,\n",
      "        333, 256, 350, 242, 345,  66,  75,  65,  81,  71,  81, 263,  53, 266,\n",
      "         70, 101, 338,  99, 355,  70,  77,  66,  76,  65,  79, 258,  78, 257,\n",
      "         82,  71,  75,  73,  76, 178])\n",
      "tensor([168, 183,  84, 144, 207, 103,  57,  79,  74, 163, 226,  20,  80, 261,\n",
      "        148, 136,  86,  79, 266,  23, 263, 180,  80, 260,  82,  83, 331,  74,\n",
      "         27,  86, 188, 176,  22,  87,  19, 159,  92,  51, 108, 326, 272, 313,\n",
      "        326, 332, 319, 341, 127, 331, 256, 203, 331, 261,  95, 331, 331, 352,\n",
      "         53, 345, 131, 252, 264, 338,  72, 340, 255, 260, 263, 274,  57, 266,\n",
      "        255])\n"
     ]
    }
   ],
   "source": [
    "with open(intermediate_filepath, \"r\") as f:\n",
    "    print(torch.tensor(encode(f.readline().split()), dtype=torch.long))\n",
    "    print(torch.tensor(encode(f.readline().split()), dtype=torch.long))\n",
    "    print(torch.tensor(encode(f.readline().split()), dtype=torch.long))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "22b699e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_games = []\n",
    "with open(intermediate_filepath, \"r\") as f:\n",
    "    for line in f:\n",
    "        game = encode(line.split())\n",
    "        if len(game) >= block_size + 1:\n",
    "            encoded_games.append(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a8184c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43978\n",
      "54\n",
      "55\n",
      "[84, 237, 148, 183, 167, 163, 80, 143, 264, 160, 46, 140, 84, 136, 169, 20, 39, 48, 272, 79, 43, 122, 84, 269, 244, 83, 22, 74, 272, 140, 275, 87, 187, 23, 272, 136, 79, 180, 226, 176, 228, 331, 80, 153, 326, 5, 348, 10, 72, 157, 258, 325, 272, 71, 214, 223, 345, 66, 72, 354, 207, 193, 191, 339, 216, 72, 70, 283, 70, 303, 258, 315, 319, 324, 319, 17, 66, 318, 325, 285]\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print (len(encoded_games))\n",
    "print (len(encoded_games[100]))\n",
    "print (len(encoded_games[200]))\n",
    "print (encoded_games[300])\n",
    "print (min([len(g) for g in encoded_games]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fe52d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(encoded_games)) # first 90% will be train, rest val\n",
    "train_data = encoded_games[:n]\n",
    "val_data = encoded_games[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "45e4307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block_from_game(game, block_sz, rnd, offset):\n",
    "    i = rnd % (len(game) - block_sz)\n",
    "    t = game[i + offset : i + block_sz + offset]\n",
    "    if len(t) != block_sz:\n",
    "        print (game)\n",
    "        print (t)\n",
    "        print (i, offset, block_sz)\n",
    "        assert False\n",
    "    return torch.tensor(t, dtype=torch.long)\n",
    "\n",
    "# data loading\n",
    "def get_batch(split, block_sz, batch_sz):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data)-1, (batch_sz, 2))\n",
    "    x = torch.stack([get_block_from_game(encoded_games[i[0]], block_sz, i[1], 0) for i in ix])\n",
    "    y = torch.stack([get_block_from_game(encoded_games[i[0]], block_sz, i[1], 1) for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eb3f314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([16, 32])\n",
      "targets:\n",
      "torch.Size([16, 32])\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train', block_sz=block_size, batch_sz=batch_size)\n",
    "\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "\n",
    "print('----')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "913f79c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess_encode\n",
    "import chess_decode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b8e41fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self):\n",
    "        self.board = chess.Board()\n",
    "        self.enc = chess_encode.EncoderBoard()\n",
    "        self.dec = chess_decode.DecoderBoard()\n",
    "        self.moves = []\n",
    "\n",
    "    def encoded_legal_moves(self):\n",
    "        return [self.enc.EncodeMove(mv, make_move=False) for mv in self.board.legal_moves]\n",
    "    \n",
    "    def make_move(self, enc_move):\n",
    "        move = self.dec.DecodeMove(enc_move)\n",
    "        self.enc.EncodeMove(move, make_move=True)\n",
    "        self.board.push(move)\n",
    "        self.moves.append(move)\n",
    "        return move\n",
    "    \n",
    "    def get_game_pgn(self):\n",
    "        return chess.Board().variation_san(self.moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4e0d09ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1939302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 359])\n",
      "tensor(6.3635, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b8a502e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.798133850097656\n",
      "1000 4.724464416503906\n",
      "2000 4.956279754638672\n",
      "3000 4.824542999267578\n",
      "4000 4.892591953277588\n",
      "5000 4.910529136657715\n",
      "6000 4.863946437835693\n",
      "7000 4.724982738494873\n",
      "8000 4.740623950958252\n",
      "9000 4.950060844421387\n",
      "10000 4.908806800842285\n",
      "11000 4.703491687774658\n",
      "12000 4.864297866821289\n",
      "13000 4.888840198516846\n",
      "14000 4.853829383850098\n",
      "15000 4.6967692375183105\n",
      "16000 4.667713165283203\n",
      "17000 4.667600154876709\n",
      "18000 4.944421768188477\n",
      "19000 4.769054889678955\n",
      "20000 4.633237361907959\n",
      "21000 4.810161590576172\n",
      "22000 4.897270202636719\n",
      "23000 4.900995254516602\n",
      "24000 4.930427551269531\n",
      "25000 4.825490951538086\n",
      "26000 4.874955177307129\n",
      "27000 4.862794876098633\n",
      "28000 4.8221917152404785\n",
      "29000 4.822365760803223\n",
      "30000 4.739196300506592\n",
      "31000 4.750077724456787\n",
      "32000 4.767266750335693\n",
      "33000 4.927359580993652\n",
      "34000 4.75062894821167\n",
      "35000 4.845069885253906\n",
      "36000 4.9533820152282715\n",
      "37000 4.647576332092285\n",
      "38000 4.791723251342773\n",
      "39000 4.736194133758545\n",
      "40000 4.6152663230896\n",
      "41000 4.74415922164917\n",
      "42000 4.7171831130981445\n",
      "43000 4.7163405418396\n",
      "44000 4.910990238189697\n",
      "45000 4.760120391845703\n",
      "46000 4.8657755851745605\n",
      "47000 4.7893829345703125\n",
      "48000 4.772848606109619\n",
      "49000 4.834311485290527\n",
      "50000 4.846802711486816\n"
     ]
    }
   ],
   "source": [
    "for steps in range(50001): # increase number of steps for good results... \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train', block_sz=block_size, batch_sz=batch_size)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if steps % 1000 == 0:\n",
    "        print(steps, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "58579434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, game):\n",
    "    # idx is (B, T) array of indices in the current context\n",
    "    for _ in range(max_new_tokens):\n",
    "        # get the predictions\n",
    "        logits, loss = model(idx)\n",
    "        # focus only on the last time step\n",
    "        logits = logits[:, -1, :] # becomes (B, C)\n",
    "\n",
    "        legal_moves = encode(game.encoded_legal_moves())\n",
    "        if len(legal_moves) == 0:\n",
    "            return idx\n",
    "\n",
    "        for i in range(vocab_size):\n",
    "            if i not in legal_moves:\n",
    "                logits[0, i] = -1000\n",
    "\n",
    "        # apply softmax to get probabilities\n",
    "        probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "        # sample from the distribution\n",
    "        idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "        \n",
    "        assert idx_next[0] in legal_moves\n",
    "\n",
    "        game.make_move(decode(idx_next.tolist()[0])[0])\n",
    "\n",
    "        # append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ca65d300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SPECIAL', 'Pawn:g2:TwoPush', 'N1:1:-2', 'N2:-1:2', 'N1:1:-2', 'N2:-1:2', 'Pawn:h7:Push', 'R2:-1:0', 'R1:1:0', 'N2:-2:-1', 'Pawn:f7:TwoPush', 'Pawn:h2:Push', 'Pawn:g7:TwoPush', 'Pawn:b2:TwoPush', 'N1:2:-1', 'Pawn:e2:CaptureRight', 'Pawn:e7:TwoPush', 'BL:g2', 'BD:c5', 'Pawn:h3:Push', 'Pawn:c7:Push', 'N1:1:2', 'N2:-2:-1', 'N1:1:2', 'Pawn:d7:Push', 'Pawn:d2:Push', 'N2:-1:-2', 'N2:2:1', 'N2:-1:2', 'BD:g5', 'N2:2:-1', 'K:0:1', 'R2:-2:0', 'R1:2:0', 'BL:d7', 'Q:d2', 'R1:1:0', 'R2:-2:0', 'R2:0:-1', 'R1:1:0', 'K:1:0', 'R2:2:0', 'R2:0:-1', 'N2:2:1', 'K:0:-1', 'N2:-2:-1', 'K:-1:1', 'BD:h6', 'R2:1:0', 'K:1:-1', 'R2:0:-1', 'Q:g5', 'Q:a5', 'Pawn:a2:Push', 'BD:d4', 'R1:1:0', 'Pawn:b7:TwoPush', 'Pawn:a3:Push', 'R1:1:0', 'R2:1:0', 'N2:1:-2', 'BD:g7', 'BD:b2', 'R1:0:1', 'Q:b6', 'N2:-1:2', 'BD:e5', 'N2:-2:-1', 'R1:0:-1', 'R1:-1:0', 'R1:-1:0', 'K:-1:0', 'R1:1:0', 'BD:f6', 'BD:f6', 'Pawn:h4:Push', 'R1:-2:0', 'N2:2:1', 'N2:-2:1', 'Q:f6', 'R1:2:0', 'Q:d6', 'R1:2:0', 'K:-1:0', 'Pawn:a7:Push', 'R2:0:1', 'R1:-1:0', 'K:-1:0', 'N2:-2:1', 'Pawn:c2:TwoPush', 'Pawn:c6:Push', 'Pawn:b4:CaptureRight', 'R1:1:0', 'K:-1:1', 'R1:-1:0', 'R2:0:1', 'Pawn:b5:Push', 'K:1:-1', 'R1:0:-6', 'K:-1:1', 'R1:2:0']\n",
      "1. g4 Nc6 2. Nf3 Nd4 3. Ne5 h6 4. Rg1 Rb8 5. Nc4 f5 6. h3 g5 7. b4 Nf3+ 8. exf3 e5 9. Bg2 Bc5 10. h4 c6 11. Nc3 Ne7 12. Nd5 d6 13. d3 Nxd5 14. Nxe5 Nc7 15. Bxg5 Ne6 16. Ke2 Rf8 17. Rc1 Bd7 18. Qd2 Rc8 19. Rge1 Rf7 20. Rcd1 Kf8 21. Rg1 Rf6 22. Ng6+ Kf7 23. Ne5+ Ke8 24. Bxh6 Rg6 25. Kf1 Rg5 26. Qxg5 Qa5 27. a3 Bd4 28. Re1 b5 29. a4 Rd8 30. Rh1 Nf4 31. Bg7 Bb2 32. Re2 Qb6 33. Nxd7+ Be5 34. Nxb6 Rd7 35. Rd2 Rc7 36. Ke1 Rd7 37. Bf6 Bxf6 38. h5 Rb7 39. Nd7 Nd5 40. Qxf6 Rxd7 41. Qxd6 Rf7 42. Kd1 a6 43. Rh2 Re7 44. Kc1 Nb6 45. c4 c5 46. bxc5 Rf7 47. Kb2 Re7 48. Rh3 b4 49. Kc1 Re1+ 50. Kb2 Rg1\n"
     ]
    }
   ],
   "source": [
    "game = Game()\n",
    "print(decode(generate(m, idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100, game=game)[0].tolist()))\n",
    "print (game.get_game_pgn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdaa49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
